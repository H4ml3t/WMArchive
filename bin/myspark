#!/bin/sh
# Author: Valentin Kuznetsov <vkuznet AT gmail [DOT] com>
# A wrapper script to submit spark job with myspark.py script
# from WMArchive project.

# test arguments
if [ "$#" -eq 0 ]; then
    echo "Usage: myspark <options>"
    echo "       myspark --help"
    exit 1
fi

# find out where WMArchive is installed on a system
wmaroot=`python -c "import WMArchive; print '/'.join(WMArchive.__file__.split('/')[:-1])"`

# set avro jars
avrojar=/usr/lib/avro/avro-mapred.jar
sparkexjar=/usr/lib/spark/examples/lib/spark-examples-1.3.0-cdh5.4.2-hadoop2.6.0-cdh5.4.2.jar

if [ "$1" == "-h" ] || [ "$1" == "--help" ] || [ "$1" == "-help" ]; then
	# run help
    python $wmaroot/Tools/myspark.py --help
else
	# submit spark job with our file, please note
    # that user may increase memory options if necessary
    # the executor and driver memory options can be given in human readable form
    # while spark yarn option should use memoryOverhead as KB value
    spark-submit --driver-class-path $avrojar:$sparkexjar \
        --executor-memory 4G \
        --driver-memory 4G \
        --conf spark.yarn.executor.memoryOverhead=4096 \
        $wmaroot/Tools/myspark.py ${1+"$@"}
fi
